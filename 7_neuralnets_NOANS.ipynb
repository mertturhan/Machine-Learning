{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will start with a simple toy implementation of a neural network and apply it to the XOR problem. In the second part we will learn how to use the [Keras toolkit](https://keras.io/) to define, train and use a practical neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR\n",
    "\n",
    "Let's start with the [XOR problem](https://en.wikipedia.org/wiki/XOR_gate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "%pylab inline --no-import-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "Define the function `xor`, which which takes a Nx2 array, where each row is an input to the logical XOR. It outputs an array of size N with the corresponding outputs.\n",
    "\n",
    "Given `X = numpy.array([[0, 0],      \n",
    "                 [0, 1],      \n",
    "                 [1, 0],      \n",
    "                 [1, 1]])`\n",
    "                 \n",
    "`xor(X)` should output `[0, 1, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(X):\n",
    "    #.........\n",
    "    return (X.sum(axis=1) == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = numpy.array([[0, 0],      # FALSE\n",
    "                 [0, 1],      # TRUE\n",
    "                 [1, 0],      # TRUE\n",
    "                 [1, 1]])     # FALSE\n",
    "y = xor(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x117d1f750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.scatter(X[:,0], X[:,1], c=y, s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "We can define a simple two layer neural network by hand which solves the XOR classification problem. The network has parameters $\\mathbf{W}$ and $\\mathbf{U}$, and computes the following:\n",
    "\n",
    "$$Y = \\sigma(U(\\sigma(WX^T))$$\n",
    "\n",
    "Where $\\mathbf{X}$ is the input array, with shape Nx2, $\\mathbf{W}$ is a 2x2 matrix, and $\\mathbf{U}$ is a 1x2 matrix. The result is a 1xN matrix (i.e. a single row vector) of XOR values.\n",
    "\n",
    "### Exercise 7.2\n",
    "\n",
    "Define function `sigma` which returns one if the input is greater than or equal to 0.5, and zero otherwise.\n",
    "\n",
    "Given `X = numpy.array([[0.1, 0.3], [0.5, 0.7]])`\n",
    "        \n",
    "`sigma(X)` should output \n",
    "\n",
    "`[[0. 0.]\n",
    "[1. 1.]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(X):\n",
    "    #...............\n",
    "    return (X>=0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90345068 0.04455437]\n",
      " [0.70679061 0.67057994]\n",
      " [0.93991733 0.76245151]]\n",
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "[[0. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "z = numpy.random.uniform(0,1,(3,2))\n",
    "print(z)\n",
    "print(sigma(z))\n",
    "print(sigma(numpy.array([[0.1, 0.3],\n",
    "            [0.5, 0.7]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.3\n",
    "\n",
    "Define function `nnet` which takes the weight matrices W and U, and the input X, and returns the result Y computed according to the formula above.\n",
    "\n",
    "Given `X = numpy.array([[0, 0],      \n",
    "                 [0, 1],      \n",
    "                 [1, 0],      \n",
    "                 [1, 1]])`\n",
    " \n",
    "`W = numpy.array([[1,-1],\n",
    "                 [-1,1]])`\n",
    "                 \n",
    "`U = numpy.array([1,1])`\n",
    "\n",
    "`nnet(W, U, X)` should output `[0, 1, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet(W,U,X):\n",
    "    Z=sigma(numpy.dot(W,numpy.transpose(X)))\n",
    "    return sigma(numpy.dot(U,Z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = numpy.array([[1,-1],\n",
    "                 [-1,1]])\n",
    "U = numpy.array([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what it outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n",
      "[0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nnet(W, U, X)\n",
    "print(y)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the outputs as a function of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a grid of points for plotting\n",
    "shape=(20,20)\n",
    "grid = numpy.array([ [i,j] for i in numpy.linspace(0,1,shape[0]) \n",
    "                               for j in numpy.linspace(0,1,shape[1]) ])\n",
    "# Apply the neural net to all the points\n",
    "y_pred = nnet(W, U, grid)\n",
    "pylab.pcolor(y_pred.reshape((20,20)))\n",
    "pylab.colorbar()\n",
    "pylab.xticks([])\n",
    "pylab.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XOR NN with Keras\n",
    "\n",
    "We'll now learn how to build a simple neural network in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Dense(32, input_dim=2))    # Input layer with 10 features\n",
    "model.add(Activation('relu'))        # Activation function\n",
    "model.add(Dropout(0.5))              # Dropout layer for regularization\n",
    "model.add(Dense(1))                  # Output layer\n",
    "model.add(Activation('sigmoid'))     # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model, specifying number of epochs, size of the minibatch, and whether to print extra information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2667 - loss: 0.7495    \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.7022  \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.5667 - loss: 0.7143\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.4667 - loss: 0.7190\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.8333 - loss: 0.6015\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2667 - loss: 0.7866  \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 0.7757    \n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.3056 - loss: 0.7160    \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.1000 - loss: 0.7201    \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.4333 - loss: 0.64899\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.5667 - loss: 0.6156\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9000 - loss: 0.6532\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7333 - loss: 0.6427\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.2667 - loss: 0.6700 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.6333 - loss: 0.6589\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2667 - loss: 0.7160  \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4333 - loss: 0.6665  \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 0.7362\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.4333 - loss: 0.8158 \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.4333 - loss: 0.67867\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7333 - loss: 0.6677\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.3667 - loss: 0.69463\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6333 - loss: 0.6496  \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2667 - loss: 0.7056  \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6465\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4333 - loss: 0.6494  6\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7333 - loss: 0.5954\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5333 - loss: 0.6196   \n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.2667 - loss: 0.71967\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1806 - loss: 0.7064    \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.8472  \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5694 - loss: 0.6137  \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.6191  \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.6333 - loss: 0.6740\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.4667 - loss: 0.7026\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.7333 - loss: 0.5872\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.2667 - loss: 0.7088  \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.8333 - loss: 0.5767\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.3667 - loss: 0.6788\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5667 - loss: 0.6163  \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4667 - loss: 0.7460  \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1667 - loss: 0.7328  75\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9000 - loss: 0.5965\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.1667 - loss: 0.7967    \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.2667 - loss: 0.7268  \n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3667 - loss: 0.6964 \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.3667 - loss: 0.68949\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2667 - loss: 0.6921    \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4667 - loss: 0.6646\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.6815  8\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2667 - loss: 0.76008399\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.6887  \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.5954\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4667 - loss: 0.7119  \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5667 - loss: 0.5936  \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.6806410\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2667 - loss: 0.7374   \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.6472  \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.5805  \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.6106\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2667 - loss: 0.6839    \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 0.7016      \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.1667 - loss: 0.703773\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 0.6251\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7333 - loss: 0.7011\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.6491\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3667 - loss: 0.6996  \n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.4333 - loss: 0.6605  \n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.3667 - loss: 0.73657\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 0.5988\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.5466  \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 0.6297\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7333 - loss: 0.5906\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.3667 - loss: 0.7382 \n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5667 - loss: 0.6442  \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 1.0000 - loss: 0.5536\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.3667 - loss: 0.70339\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.5863\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.5849  \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4444 - loss: 0.6949  \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.687655\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.5939  \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.6885  \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.6566  \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.2667 - loss: 0.6642  \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.1806 - loss: 0.7530    \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.5667 - loss: 0.6959\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.6588\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.5518  \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.6333 - loss: 0.7108\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7333 - loss: 0.5957\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9000 - loss: 0.6514\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6333 - loss: 0.6546  \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7333 - loss: 0.6224\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5906  \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5944  \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 0.6273\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.5568\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6158  \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.5313  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30e7c3390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1          x2          F(x1, x2)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "[[0.         0.         0.49950129]\n",
      " [0.         1.         0.54238069]\n",
      " [1.         0.         0.54790151]\n",
      " [1.         1.         0.45423815]]\n"
     ]
    }
   ],
   "source": [
    "print(\"   x1          x2          F(x1, x2)\")\n",
    "print(np.hstack([X, model.predict(X)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGFCAYAAAALqAHuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlmElEQVR4nO3df2xV933/8de559q+JmC3+xKM2zjAotRBeP0GGX0TkxJpdeuJVFkWqSorG5G+Aq007RaKog6+gdGwkWhNhjxVMoqjrhMjXZHiftdJsbY4VVBpiBaFkSr6NkkpSWrP2KWwxTY/7HvvOef7B8m59mzMtc8b7M/h+ZDOH76+530/xz/u+77fn885x4uiKBIAAHBaZq4HAAAAkiOhAwCQAiR0AABSgIQOAEAKkNABAEgBEjoAAClAQgcAIAWy5TwpDEOdPn1aixYtkud513pMAACHRVGkkZERfeITn1Amc+3qxtHRUeXz+cRxKisrlcvlDEY0t8pK6KdPn1ZDQ8O1HgsAIEX6+vp0yy23XJPYo6OjWrFsoQbPBIljLV26VO+9957zSb2shL5o0SJJ0q/+fblqFib/tHWqcCFxjPF+UbjZNN7JsaWm8d69uNg0Xt/Fj5nG+/X5RWaxhj9YYBZLkrwPKkzjVQzZVguVH5iGU9WI7YUbK4ft4lWcL5rFkqTsRdt4/vmCabzMhVHTeLp4yTRcODxsF8t4bEUV9FN1x7njWsjn8xo8E+hXx5erZtHs/6+HR0Ita35f+Xz+xkjoH7XZaxZmVLPIT/yiCwu2b6oLCsnHNF6uoqwfS9kqM5Wm8bJelWk8P7SLlxmz/YfwxmwTuj9m+7fn2/4q5I/ZJvRshV28bNY4oRvH833b323GN74qdiZ5JTle6Nm9r4Se7e9CH/7orscU7cJFnhYumv3rhErPNLJt5gIA4DoKolBBgs9eQRTaDWaOscodAIAUoEIHADgrVKRQsy/Rk+w735DQAQDOChUqSdM82d7zCy13AABSgAodAOCsIIoURLNvmyfZd74hoQMAnMUcegktdwAAUoAKHQDgrFCRAip0SSR0AIDDaLmXkNABAM5iUVwJc+gAAKQAFToAwFnhh1uS/dOChA4AcFaQcFFckn3nG1ruAACkABU6AMBZQaSEt0+1G8tcm1FCPx+OKRMmL+ovRLafIy6EVabxLoaVpvEuBRW28Yq28fIFw99H0bbp4xU903iZgmk4ZYq28bzAOF44f9+tvDRNXpYjtD1gz/fNYvkLF5rFkqQoykvnTUNeEXPoJbTcAQBIAVruAABnhfIUaPadvDDBvvMNCR0A4Kwwurwl2T8taLkDAJACVOgAAGcFCVvuSfadb0joAABnkdBLSOgAAGeFkacwSrAoLsG+8w1z6AAApAAJHQDgrI9a7km22ejo6NCKFSuUy+XU3Nyso0ePXvG5R44cked5k7a33357yuf/4Ac/kOd5+oM/+IMZjYmWOwDAWYEyChLUprO5OOPhw4e1bds2dXR06J577tEzzzyj9evX6+c//7luvfXWK+73zjvvqKamJv765ptvnvScX/3qV3r00Ue1bt26GY+LCh0AgBnYv3+/Nm/erC1btmjlypVqb29XQ0ODDhw4MO1+S5Ys0dKlS+PN/2+X7w2CQH/0R3+kxx9/XL/9278943GR0AEAzoo+XBQ32y36cFHc8PDwhG1sbGzK18vn8zp+/Lja2tomPN7W1qZjx45NO9bVq1ervr5era2tevnllyd9f+/evbr55pu1efPmWf0sSOgAAGdZzaE3NDSotrY23p588skpX+/s2bMKgkB1dXUTHq+rq9Pg4OCU+9TX16uzs1NdXV364Q9/qMbGRrW2tuonP/lJ/JxXXnlF3/3ud/Xss8/O+mfBHDoA4IbX19c3YX67qmr6u3h63sTFdFEUTXrsI42NjWpsbIy/bmlpUV9fn55++mnde++9GhkZ0R//8R/r2Wef1eLFi2d9DCR0AICzgiijIEqwKO7Da7nX1NRMSOhXsnjxYvm+P6kaP3PmzKSqfTp33323Dh06JEk6deqU3n//fd1///3x98MPb7ebzWb1zjvv6LbbbrtqTBI6AMBZoTyFCWaPQ83s7iyVlZVqbm5WT0+PHnzwwfjxnp4ePfDAA2XHOXHihOrr6yVJd9xxh958880J39+1a5dGRkb0t3/7t2poaCgrJgkdAOCsubj06/bt27Vp0yatWbNGLS0t6uzsVG9vr7Zu3SpJ2rlzp/r7+3Xw4EFJUnt7u5YvX65Vq1Ypn8/r0KFD6urqUldXlyQpl8upqalpwmt87GMfk6RJj0+HhA4AwAxs2LBB586d0969ezUwMKCmpiZ1d3dr2bJlkqSBgQH19vbGz8/n83r00UfV39+v6upqrVq1Si+88ILuu+8+03F5URRdtd8wPDys2tpa/b+3lmjRouQL498tLEocY7y3x+pN450cXWoa770L/8M0Xv9IrWm8c8M3mcUq/Nf0C0lmKvuB7WfOqv8yDafKYeN4I7Y3Z644H9rFujCbS3BcWfZC0TRe5kLeNt75S6bxdGnUNt7V37rLl7E94akYjuml089oaGiorHnp2fgoL/3fn92umxb5V9/hCi6MBHrwf568pmO9XqjQAQDOujyHnuDmLCm62xrnoQMAkAJU6AAAZ4UJr+U+01Xu8xkJHQDgrOTnoacnodNyBwAgBajQAQDOCpW5rheWmc9I6AAAZwWRpyBKcGGZBPvON7TcAQBIASp0AICzgoSr3ANa7gAAzL0wyihMsMo9TNEqdxI6AMBZVOglzKEDAJACVOgAAGeFSrZS3e72RXOPhA4AcFby89DT06hOz5EAAHADo0IHADgr+bXc01PXktABAM7ifuglM0roQ6GvIEz+aeZCVJk4xngXwyrbeEGFabzRou3npnzgm8YLCoafUC1jScoUTMPJKxrHM15RYx0PCWSMK7cF1bbxfLvxRVnbY42CCum0aUiUgQodAOAsWu4lJHQAgLOSX1gmPQk9PUcCAMANjAodAOCsMPIUJrmwTIpun0pCBwA4K0zYck/ThWVI6AAAZyW/21p6Enp6jgQAgBsYFToAwFmBPAUJLg6TZN/5hoQOAHAWLfeS9BwJAAA3MCp0AICzAiVrmwd2Q5lzJHQAgLNouZek50gAALiBUaEDAJzFzVlKSOgAAGdFCe+HHqXotLX0fDQBAOAGRoUOAHAWLfcSEjoAwFncba1kRgl9KMipGCT/NDMSVCeOMTFezjTehWKVabyLxQrTeGMF289hYdE3i5Up2v5zZIqm4eQZn3RqHc+aF831CK4j40IrXGD7PqCs7QAjw3iRbzu2oHj9qt4g4d3Wkuw736TnSAAAuIHRcgcAOIuWewkJHQDgrFAZhQmazUn2nW/ScyQAANzAqNABAM4KIk9BgrZ5kn3nGxI6AMBZzKGX0HIHACAFqNABAM6KEt4+NeJKcQAAzL1AnoIEN1hJsu98k56PJgAA3MCo0AEAzgqjZAvbwhRdHpmEDgBwVphwDj3JvvMNCR0A4KxQnsIE8+BJ9p1v0vPRBACAGxgVOgDAWVwproSEDgBwFnPoJek5EgAAbmAzqtCHwmoVQj/xi34QLEgcY7zzQZVpvIvFStN4+cC2EVIoJv8djBcV7FpOXsEs1OV4Rdt4mdA2nlJ0ysv1Zl0YhdW2/7dh1rYVG/m2BxwZjs/6WIuFwDTedEIlvJZ7ihbF0XIHADgrSrjKPUpRQqflDgBAClChAwCcxe1TS0joAABnscq9JD1HAgDADYwKHQDgLFruJSR0AICzuJZ7CQkdAOAsKvQS5tABAEgBKnQAgLOo0EtI6AAAZ5HQS2i5AwCQAlToAABnUaGXUKEDAJwVqXTq2my22d4wsaOjQytWrFAul1Nzc7OOHj16xeceOXJEnudN2t5+++34Oc8++6zWrVunj3/84/r4xz+uz33uc3rttddmNCYSOgAAM3D48GFt27ZNjz32mE6cOKF169Zp/fr16u3tnXa/d955RwMDA/F2++23x987cuSIvvzlL+vll1/Wq6++qltvvVVtbW3q7+8ve1wkdACAsz5quSfZZmr//v3avHmztmzZopUrV6q9vV0NDQ06cODAtPstWbJES5cujTff9+PvPffcc3r44Yd155136o477tCzzz6rMAz14x//uOxxkdABAM6ySujDw8MTtrGxsSlfL5/P6/jx42pra5vweFtbm44dOzbtWFevXq36+nq1trbq5Zdfnva5Fy9eVKFQ0G/91m+V/bMgoQMAbngNDQ2qra2NtyeffHLK5509e1ZBEKiurm7C43V1dRocHJxyn/r6enV2dqqrq0s//OEP1djYqNbWVv3kJz+54nh27NihT37yk/rc5z5X9jHMaJX7UFitfJB8YfxQsCBxjPHOB1Wm8S4WK0zjjRZtTyYICv7VnzQDXsHuc12mYLti1AtMw0mhcTxr0WyX6Fx71ouBg2rb/4vQtx1gVGEbz3x8hvFC4/OdisbvUdOxWuXe19enmpqa+PGqqunziudNfM0oiiY99pHGxkY1NjbGX7e0tKivr09PP/207r333knP//a3v61//Md/1JEjR5TL5co+Fk5bAwA4yyqh19TUTEjoV7J48WL5vj+pGj9z5sykqn06d999tw4dOjTp8aefflpPPPGEXnrpJX36058uO55Eyx0A4LAo8hJvM1FZWanm5mb19PRMeLynp0dr164tO86JEydUX18/4bGnnnpKf/mXf6l/+Zd/0Zo1a2Y0LokKHQCAGdm+fbs2bdqkNWvWqKWlRZ2dnert7dXWrVslSTt37lR/f78OHjwoSWpvb9fy5cu1atUq5fN5HTp0SF1dXerq6opjfvvb39bu3bv1/e9/X8uXL487AAsXLtTChQvLGhcJHQDgrLm4H/qGDRt07tw57d27VwMDA2pqalJ3d7eWLVsmSRoYGJhwTno+n9ejjz6q/v5+VVdXa9WqVXrhhRd03333xc/p6OhQPp/XF7/4xQmvtWfPHn3rW98qa1wkdACAs+bq0q8PP/ywHn744Sm/9/d///cTvv7mN7+pb37zm9PGe//992c1jvGYQwcAIAWo0AEAzprNwrb/vn9akNABAM7ibmsltNwBAEgBKnQAgLNouZeQ0AEAzooSttzTlNBpuQMAkAJU6AAAZ0VKdk+j+Xs7pJkjoQMAnBXKk3edrxQ3X5HQAQDOYlFcCXPoAACkABU6AMBZYeTJ48IykmaY0IeCBcoHyT8DDBWrE8cY70KxyjTexWKFabx8wfZzU5C3bax4Bbs/6EzRLJQkyQts41nzkqzGuQ4s36uKC3y7YJIi3/aNNDQuT8zHZ/vjMz1e62O1fo+aThQlXBQ3v/+FZ4SWOwAAKUDLHQDgLBbFlZDQAQDOIqGX0HIHACAFqNABAM5ilXsJCR0A4CxWuZfQcgcAIAWo0AEAzrpcoSdZFGc4mDlGQgcAOItV7iUkdACAsyIluwVqigp05tABAEgDKnQAgLNouZeQ0AEA7qLnHqPlDgBAClChAwDclbDlbnqP4TlGQgcAOIsrxZXQcgcAIAWo0AEAzmKVe8mMEvpwUK18UJH4RYeL1YljjHexWGkab7SY/BjHyxd903hR0bax4hfs/qC90CzU5XgpaoeVxbN9cykusIsX2v4ZKzKOF2Ztf3bm45vHPz/rYw3GbONNK/KSzYOnKKHTcgcAIAVouQMAnMWiuBISOgDAXVxYJkZCBwA4i0VxJcyhAwCQAlToAAC3pahtngQJHQDgLFruJbTcAQBIASp0AIC7WOUeI6EDABzmfbgl2T8daLkDAJACVOgAAHfRco+R0AEA7iKhx2i5AwCQAlToAAB3cfvUGAkdAOAs7rZWQkIHALiLOfTYjBL6cLFaY8WKxC86XMwljjHeRYMxjTdWtP2cU8zbxvPytksfvKJdy8kLzEJdZvzP5hnHizzbdl2h2jScIsM/vdC3iyVJ0XyPZ7zCKDQunyyP1/pnF9i+JaNMVOgAAHcxhx4joQMAnOVFyTpv1l27ucRpawAApAAVOgDAXSyKi5HQAQDuYg49RssdAIAUoEIHALiLlnuMhA4AcBcJPUbLHQCAFKBCBwC4iwo9RkIHALiLVe4xEjoAwFlcKa6EOXQAAFKACh0A4C7m0GNU6AAApAAJHQCAFKDlDgBwlqeEi+LMRjL3SOgAAHdx2lpsRgl9pFilsWJl4hc9X6xKHGO8C4XkYxpvrGD7OSco2M5seAXbP0AvMA03r1n/7xYX2MaLfON4hn96ofXYjMsJ85/dPP5dSLbjC41/F9bx5qOOjg499dRTGhgY0KpVq9Te3q5169ZN+dwjR47od3/3dyc9/tZbb+mOO+6Iv+7q6tLu3bt16tQp3Xbbbdq3b58efPDBssfEHDoAwF2RwTZDhw8f1rZt2/TYY4/pxIkTWrdundavX6/e3t5p93vnnXc0MDAQb7fffnv8vVdffVUbNmzQpk2b9LOf/UybNm3Sl770Jf3bv/1b2eMioQMA3GWU0IeHhydsY2NjV3zJ/fv3a/PmzdqyZYtWrlyp9vZ2NTQ06MCBA9MOdcmSJVq6dGm8+X6pzdLe3q7Pf/7z2rlzp+644w7t3LlTra2tam9vL/tHQUIHANzwGhoaVFtbG29PPvnklM/L5/M6fvy42traJjze1tamY8eOTfsaq1evVn19vVpbW/Xyyy9P+N6rr746Kebv/d7vXTXmeDfATAcAIK2sLv3a19enmpqa+PGqqqnXep09e1ZBEKiurm7C43V1dRocHJxyn/r6enV2dqq5uVljY2P6h3/4B7W2turIkSO69957JUmDg4MzijkVEjoAwF1GV4qrqamZkNCvxvMmrrCNomjSYx9pbGxUY2Nj/HVLS4v6+vr09NNPxwl9pjGnQssdAOCu67wobvHixfJ9f1LlfObMmUkV9nTuvvtunTx5Mv566dKliWOS0AEAKFNlZaWam5vV09Mz4fGenh6tXbu27DgnTpxQfX19/HVLS8ukmC+++OKMYtJyBwA4ay5un7p9+3Zt2rRJa9asUUtLizo7O9Xb26utW7dKknbu3Kn+/n4dPHhQ0uUV7MuXL9eqVauUz+d16NAhdXV1qaurK475yCOP6N5779Vf//Vf64EHHtCPfvQjvfTSS/rpT39a9rhI6AAAd83BleI2bNigc+fOae/evRoYGFBTU5O6u7u1bNkySdLAwMCEc9Lz+bweffRR9ff3q7q6WqtWrdILL7yg++67L37O2rVr9YMf/EC7du3S7t27ddttt+nw4cO66667yh6XF0XRVT+fDA8Pq7a2Vv/7yJdUuTD5Vdl+M7YocYzxzl2yvVzXb84vNI13YThnGs/7oMI0Xva83cxL9pJZKEmSbx3vyqeWzo7xlefm89XJuFJcwng30pXiRkf13p7/o6GhoRktNJuJj/LSisefUCY3+/fY6zHW64UKHQDgLu6HHiOhAwCcNRdz6PMVq9wBAEgBKnQAgLtoucdI6AAAdyVsuacpodNyBwAgBajQAQDuouUem1FCPx/kVFFMfh76+ULyGONdNI5XKNqegBoVbBshmcD25GcvNAw2z/85AttLApifvzufz82ez+dRS9fgd+Hb/jHbnydvNz7r322YsXxTuQoSeowKHQDgLE5bK2EOHQCAFCChAwCQArTcAQDuYg49RoUOAEAKUKEDAJzForgSEjoAwG0pSspJ0HIHACAFqNABAO5iUVyMhA4AcBZz6CW03AEASAEqdACAu2i5x0joAABn0XIvIaEDANxFhR5jDh0AgBSgQgcAuIsKPUZCBwA4izn0ElruAACkwIwq9POFKlUUKhO/6AWDGONdyleYxgsKvmk8r2D7uckLTMPN65ZTcYFtvMj2V2seLzTumUW+3S83msdjk6TIujyxHl/WNp5nOT7jY1W2aBtvOrTcY7TcAQDuIqHHaLkDAJACVOgAAGexKK6EhA4AcBct9xgtdwAAUoAKHQDgLFruJSR0AIC7aLnHSOgAAHeR0GPMoQMAkAJU6AAAZ3kfbkn2TwsSOgDAXbTcY7TcAQBIASp0AICzOG2thIQOAHAXLfcYLXcAAFKACh0A4LYUVdlJkNABAM5iDr1kRgl9JF+pbEVV4he9VKhIHGO8sYLt55KgYDwTUTQ+03Ee/wEG1bbxQuOPnFHW9ocX+abhFPnG47M8XuOxyfh3YT0+LxOaxssYjy/j243Pz9oea5AZM42H8lChAwDcxaK4GAkdAOAsWu4lJHQAgLuo0GOctgYAQApQoQMAnEXLvYSEDgBwFy33GC13AABSgAodAOAuKvQYCR0A4Czm0EtouQMAkAJU6AAAd9Fyj5HQAQDO8qJIXjT7rJxk3/mGljsAAClAhQ4AcBct9xgJHQDgLFa5l5DQAQDuokKPMYcOAEAKUKEDAJxFy71kRgn9Qr5KfrYq8YteuJQ8xnjFMd80XpS3bVxkQtNw5oo3Gf5F+7b/HaHtr1bK2o4vMj5eL2v8x2I4voxvO7aM8bFmjH8XWT8wjmd7vJbxssZvUkE0ZhpvWrTcY7TcAQBIAVruAABn0XIvIaEDANxFyz1Gyx0AgBnq6OjQihUrlMvl1NzcrKNHj5a13yuvvKJsNqs777xz0vfa29vV2Nio6upqNTQ06Bvf+IZGR0fLHhMJHQDgtI/a7rPZZuPw4cPatm2bHnvsMZ04cULr1q3T+vXr1dvbO+1+Q0NDeuihh9Ta2jrpe88995x27NihPXv26K233tJ3v/tdHT58WDt37ix7XCR0AIC7oij5NkP79+/X5s2btWXLFq1cuVLt7e1qaGjQgQMHpt3vK1/5ijZu3KiWlpZJ33v11Vd1zz33aOPGjVq+fLna2tr05S9/Wa+//nrZ4yKhAwCclaQ6H1+lDw8PT9jGxqY+9S6fz+v48eNqa2ub8HhbW5uOHTt2xXF+73vf06lTp7Rnz54pv/+Zz3xGx48f12uvvSZJevfdd9Xd3a0vfOELZf8sWBQHALjhNTQ0TPh6z549+ta3vjXpeWfPnlUQBKqrq5vweF1dnQYHB6eMffLkSe3YsUNHjx5VNjt12v3DP/xD/eY3v9FnPvMZRVGkYrGor371q9qxY0fZx0BCBwC4y2iVe19fn2pqauKHq6qmvwCa53kTw0TRpMckKQgCbdy4UY8//rg+9alPXTHekSNHtG/fPnV0dOiuu+7SL3/5Sz3yyCOqr6/X7t27yzoUEjoAwFleeHlLsr8k1dTUTEjoV7J48WL5vj+pGj9z5sykql2SRkZG9Prrr+vEiRP6+te/LkkKw1BRFCmbzerFF1/UZz/7We3evVubNm3Sli1bJEm/8zu/owsXLuhP/uRP9NhjjymTufoMOXPoAACUqbKyUs3Nzerp6ZnweE9Pj9auXTvp+TU1NXrzzTf1xhtvxNvWrVvV2NioN954Q3fddZck6eLFi5OStu/7iqJIUZkL96jQAQDumoMLy2zfvl2bNm3SmjVr1NLSos7OTvX29mrr1q2SpJ07d6q/v18HDx5UJpNRU1PThP2XLFmiXC434fH7779f+/fv1+rVq+OW++7du/X7v//78v3ybmpBQgcAOGsuLv26YcMGnTt3Tnv37tXAwICamprU3d2tZcuWSZIGBgauek76f7dr1y55nqddu3apv79fN998s+6//37t27ev7BheVEYtPzw8rNraWq1+frv8BcnvlDZyKZc4xnj5UdvPJcEl23iZi7a3DMuMTV54kURkOTzutpYId1tLEI+7rc0+lvXd1i6M6d+/uF9DQ0NlzUvPxkd56X898FfKVsw+pxQLo3rtR7uu6VivFyp0AIC7ZnlxmAn7pwQJHQDgLO62VsIqdwAAUmBGFfrIpSr5XvL57/yY8Zy38Ry6N2b7Ocf6E2BQbRzQcF45Mp4X9YznvD3jeUzfeHzW89S+YbyKrO2csuXYJKnSeM67wjhepV80jmc3vsqM7bEWlDeNNy1unxqj5Q4AcBYt9xISOgDAXSyKizGHDgBAClChAwCcRcu9hIQOAHAXi+JitNwBAEgBKnQAgLNouZeQ0AEA7gqjy1uS/VOCljsAAClAhQ4AcBeL4mIkdACAszwlnEM3G8nco+UOAEAKUKEDANzFpV9jJHQAgLM4ba2EhA4AcBeL4mLMoQMAkAJU6AAAZ3lRJC/BPHiSfecbEjoAwF3hh1uS/VNiRgm9MJpVkEn+GSAYtf0c4Y3Zzhx4ge2ZiWHO9i8mytp+ovSyduPzDWNJkl9hHM+3jVdZUTSNl7Uenx/YxcraHmtFxm5skpTzbceXMz7enF8wjVeZsRtftfHY8pFtPJSHCh0A4Cxa7iUkdACAu1jlHmOVOwAAKUCFDgBwF1eKi5HQAQDO4kpxJbTcAQBIASp0AIC7aLnHSOgAAGd54eUtyf5pQUIHALiLCj3GHDoAAClAhQ4AcBcXlomR0AEAzuLSryW03AEASAEqdACAu1gUFyOhAwDcFSnZPc3Tk89puQMAkAZU6AAAZ7EormRGCT0YzSrykn8G8Eb9xDHGywSm4RRWG186KGc7QD9rO75shd34fN92bBVZ259dVbZoGq/SeHy5bME03gLDeJaxJCnn28ar9vPG8Yx/Fxnb8S0wPF7rsY0Gtv9n04qUcA7dbCRzjpY7AAApQMsdAOAuVrnHSOgAAHeFkryE+6cECR0A4CwWxZUwhw4AQApQoQMA3MUceoyEDgBwFwk9RssdAIAUoEIHALiLCj1GQgcAuIvT1mK03AEASAEqdACAszgPvYSEDgBwF3PoMVruAACkABU6AMBdYSR5CarsMD0VOgkdAOAuWu4xEjoAwGEJE7rSk9CZQwcAIAVmVKFnLvrKRH7iF/WKSa4CMFlYbXxlgCrbeBW5om28Ctt4lRWBWaxc1nZsuWzBNF51hW28nG97vAuyedN4N/l28W7KjpnFkqSFvm28BcbxFmVGTeMtyBj/bjN2x7vAMJYkXczbvadcFS33GC13AIC7wkiJ2uYpWhRHyx0AgBSgQgcAuCsKL29J9k8JEjoAwF3MocdouQMAkAJU6AAAd7EoLkZCBwC4i5Z7jJY7AAApQEIHALgrUqlKn9U2u5ft6OjQihUrlMvl1NzcrKNHj5a13yuvvKJsNqs777xz0vc++OADfe1rX1N9fb1yuZxWrlyp7u7ussdEyx0A4K45aLkfPnxY27ZtU0dHh+655x4988wzWr9+vX7+85/r1ltvveJ+Q0NDeuihh9Ta2qpf//rXE76Xz+f1+c9/XkuWLNHzzz+vW265RX19fVq0aFHZ4yKhAwDcFYaSEpxLHs583/3792vz5s3asmWLJKm9vV3/+q//qgMHDujJJ5+84n5f+cpXtHHjRvm+r3/6p3+a8L2/+7u/03/+53/q2LFjqqiokCQtW7ZsRuOi5Q4AuOENDw9P2MbGpr6+fT6f1/Hjx9XW1jbh8ba2Nh07duyK8b/3ve/p1KlT2rNnz5Tf/+d//me1tLToa1/7murq6tTU1KQnnnhCQVD+dfFJ6AAAdyWaPy+16xsaGlRbWxtvV6q0z549qyAIVFdXN+Hxuro6DQ4OTrnPyZMntWPHDj333HPKZqdujL/77rt6/vnnFQSBuru7tWvXLv3N3/yN9u3bV/aPgpY7AMBdRnPofX19qqmpiR+uqqqadjfPm3jX0CiKJj0mSUEQaOPGjXr88cf1qU996orxwjDUkiVL1NnZKd/31dzcrNOnT+upp57SX/zFX5R1KCR0AMANr6amZkJCv5LFixfL9/1J1fiZM2cmVe2SNDIyotdff10nTpzQ17/+dUmXk3cURcpms3rxxRf12c9+VvX19aqoqJDvl25RvnLlSg0ODiqfz6uysvKqY6PlDgBwVxgl32agsrJSzc3N6unpmfB4T0+P1q5dO+n5NTU1evPNN/XGG2/E29atW9XY2Kg33nhDd911lyTpnnvu0S9/+UuF4xbp/eIXv1B9fX1ZyVyiQgcAOCyKQkUJ7pg2m323b9+uTZs2ac2aNWppaVFnZ6d6e3u1detWSdLOnTvV39+vgwcPKpPJqKmpacL+S5YsUS6Xm/D4V7/6VX3nO9/RI488oj/90z/VyZMn9cQTT+jP/uzPyh7XjBJ6puAp40+eI5ipoNr4dnXV5a8CLEc2VzCNt6B66tWSs7WwKm8aL5e1O94FhrGuTTzb30W1bzu+hb7x34phvEX+qFmsy/EumcZbkLH9v1iUsR1fTcb452cY7yavaBZLks5XpOeWpFPZsGGDzp07p71792pgYEBNTU3q7u6OTzMbGBhQb2/vjGI2NDToxRdf1De+8Q19+tOf1ic/+Uk98sgj+vM///OyY3hRdPXVBMPDw6qtrdXyv9qnTC43o0FOxTyh32Sc0Ktt36RvWkBCnz/xSOizRUJP5oZK6COh1qz6tYaGhsqal56Nj/JS68ceUtYrryU9lWKU148/OHhNx3q90HIHALgrSni3NW7OAgAA5hMqdACAu8JQ8hJM4yZYUDffkNABAO6i5R4joQMAnBWFoaIEFXqSU97mG+bQAQBIASp0AIC7aLnHSOgAAHeFkeSR0CVa7gAApAIVOgDAXVEkKclpa+mp0EnoAABnRWGkKEHLvYyrnzuDljsAAClAhQ4AcFcUKlnLPT3noZPQAQDOouVeQssdAIAUKKtC/+gTTDhqc//dMEl7ZCoZ2/uhh5HtPa4D2d6nuVg0jmd4z/FC1va+ygXj+6Hnfdufne/bHu+Y8f3Vs4bxKoyPNWscT57t+4Bv/L5iHc/L2L2PJrl06lTOn78c73pUv8VoLFHbvCjb/7m55EVl/MT/4z/+Qw0NDddjPACAlOjr69Mtt9xyTWKPjo5qxYoVGhwcTBxr6dKleu+995TL5QxGNnfKSuhhGOr06dNatGiRPM+7HuMCADgqiiKNjIzoE5/4hDKZazezOzo6qnw+edetsrLS+WQulZnQAQDA/MaiOAAAUoCEDgBACpDQAQBIARI6AAApQEIHACAFSOgAAKQACR0AgBT4/3lCEAMMrek3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the neural net to all the points\n",
    "y_pred = model.predict(grid)\n",
    "pylab.pcolor(y_pred.reshape((20,20)))\n",
    "pylab.colorbar()\n",
    "pylab.xticks([])\n",
    "pylab.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with NN on iris\n",
    "\n",
    "We will now define and train a neural network model for regression on the iris data.\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "# Inputs\n",
    "X = numpy.array(data.data[:,0:3], dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.data[:,3], dtype='float32')\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.4\n",
    "\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 1, activation: linear\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: mean squared error\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "\n",
    "Compute mean absolute error and r-squared the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mertturhan/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim=3, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "optimizer=Adam(learning_rate=0.08)\n",
    "model.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "0.5746231\n",
      "0.22500646114349365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred = model.predict(X_val)\n",
    "print(mean_absolute_error(y_val, y_pred))\n",
    "print(r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's now do classification. The target is a categorical vector. It will need to be transformed to an array of dummies. This transform is also called one-hot encoding.\n",
    "This can be done manually, but sklearn.preprocessing has some utilities that make it simple:\n",
    "- OneHotEncoder\n",
    "- LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "X = numpy.array(data.data, dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.target, dtype='int32')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "\n",
    "# One-hot Indicator array for classes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)\n",
    "\n",
    "print(Y_train[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.5\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 3, activation: softmax\n",
    "\n",
    "NB: softmax is a generalization of inverse logit to more than 2 classes. It converts class scores to class probabilities, while making sure than they sum up to 1:\n",
    "\n",
    "```\n",
    "def softmax(x):\n",
    "    z = numpy.exp(x)\n",
    "    return z/numpy.sum(z)\n",
    "```\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: categorical_crossentropy\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "Use the method `.predict_classes` to predict the targets on validation data.\n",
    "Compute the classification accuracy using `accuracy_score` from `sklearn.metrics` on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(4,)))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.10)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Accuracy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_prob = model.predict(X_val)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_val_labels = np.argmax(y_pred_prob, axis=1)  # Ensure validation labels match the format\n",
    "accuracy = accuracy_score(y_val_labels, y_pred)\n",
    "print(f\"Accuracy Score: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (100,)\n",
      "(50, 4) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, axis=0))\n",
    "print(np.unique(y_val, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26338887 0.28194055 0.45467058]\n",
      " [0.282335   0.2791826  0.43848243]\n",
      " [0.29719037 0.25800553 0.44480407]\n",
      " [0.39107534 0.23914894 0.36977574]\n",
      " [0.39974457 0.22298475 0.37727073]\n",
      " [0.3947252  0.23301406 0.3722608 ]\n",
      " [0.37481835 0.25678226 0.36839938]\n",
      " [0.29409316 0.26368654 0.4422203 ]\n",
      " [0.2514144  0.27679375 0.47179192]\n",
      " [0.38966882 0.23769578 0.37263542]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 0 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 0 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_val_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.6\n",
    "\n",
    "\n",
    "Train a neural network classifier on the handwritten digits dataset. \n",
    "This dataset comes with scikit learn and can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    pylab.subplot(2, 5, index + 1)\n",
    "    pylab.axis('off')\n",
    "    pylab.imshow(image,cmap=plt.cm.gray_r)\n",
    "    pylab.title('%i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are in `digits.target` and the pixel values flattened into an array are in `digits.data`.\n",
    "\n",
    "Train a classifier on the first 1000 of the images, and evaluate on the rest. \n",
    "Before testing the neural network model, check the classification error rate of a logistic regression classifier as a baseline using `LogisticRegression` from `sklearn.linear_model`.\n",
    "\n",
    "\n",
    "Remember to convert the targets to the one-hot representation for training the neural network using `LabelBinarizer`.\n",
    "\n",
    "Some things to try when training a neural network model for this dataset:\n",
    "\n",
    "- start with two or three hidden layers\n",
    "- use between 32 to 128 units in each layer\n",
    "- try different learning rates in the Adam optimizer (lr=0.001, lr=0.0001) and monitor the loss function\n",
    "- train for at least 100 epochs\n",
    "- try the `relu` activation function instead of `tanh`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mertturhan/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9272271016311167"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "\n",
    "X_train = digits.images[:1000,:]\n",
    "y_train = digits.target[:1000]\n",
    "X_test = digits.images[1000:,:]\n",
    "y_test = digits.target[1000:]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "onehot=LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_test = onehot.fit(y_test)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 8)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 2.4723\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 2.0119\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 1.7287\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 1.4737\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 1.2762\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 1.1019\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.9322\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.8452\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.7390\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.6742\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.5690\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.5306\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.4762\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.4394\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.3886\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.3637\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.3278\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.3107\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.2746\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.2526\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.2335\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.2312\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.2060\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.1961\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.1848\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.1678\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.1600\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.1317\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.1457\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.1246\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.1219\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.1185\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.0971\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.0986\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.0959\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0897\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.0838\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.0790\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0711\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.0708\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 0.0716\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.0621\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 0.0609\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0569\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 0.0512\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 0.0613\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.0463\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0435\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.0434\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 0.0431\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 0.0386\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 0.0377\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 0.0321\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.0337\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.0330\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.0287\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.0267\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.0275\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.0305\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.0229\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.0280\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.0227\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 0.0210\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.0208\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.0202\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.0204\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 0.0172\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 0.0168\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.0161\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 0.0144\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.0155\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.0157\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.0141\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.0132\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.0125\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - loss: 0.0117\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - loss: 0.0116\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 0.0113\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 0.0112\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 0.0102\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 0.0096\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.0090\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 0.0093\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.0088\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.0084\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.0078\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 0.0080\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.0077\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 0.0067\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.0067\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - loss: 0.0065\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.0065\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.0061\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.0055\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.0060\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.0055\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 0.0050\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.0049\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x315f807d0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "          \n",
    "optimizer=Adam(learning_rate=0.0001)\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=16, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "(1000, 64)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
